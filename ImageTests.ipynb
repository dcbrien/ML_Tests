{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing imgage in python\n",
    "# Let's generate a set of data of simple shapes and then create a deep network to classify them\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "h=128\n",
    "w=128\n",
    "\n",
    "NUM_SAMP = 5000\n",
    "\n",
    "x_data=np.empty([NUM_SAMP*3, h, w, 3])\n",
    "\n",
    "for i in range(NUM_SAMP):\n",
    "    # Circles\n",
    "    img = np.zeros((h,w,3), np.uint8)\n",
    "\n",
    "    cv2.circle(img, (random.randint(0, h-1), random.randint(0, w-1)), random.randint(10, 50), (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)), -1)\n",
    "    x_data[i,:,:,:] = img/255\n",
    "    \n",
    "    # Rectangles\n",
    "    img = np.zeros((h,w,3), np.uint8)\n",
    "    cv2.rectangle(img, (random.randint(0, h-1), random.randint(0, w-1)), (random.randint(0, h-1), random.randint(0, w-1)), \n",
    "                 (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)), -1)\n",
    "    x_data[i+NUM_SAMP,:,:,:] = img/255\n",
    "    \n",
    "    # Triangles\n",
    "    img = np.zeros((h,w,3), np.uint8)\n",
    "    \n",
    "    pts = np.array([[random.randint(0, h-1), random.randint(0, w-1)], [random.randint(0, h-1), random.randint(0, w-1)], [random.randint(0, h-1), random.randint(0, w-1)]])\n",
    "    cv2.fillPoly(img, [pts], (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))\n",
    "    x_data[i+NUM_SAMP*2,:,:,:] = img/255\n",
    "\n",
    "y_data=np.concatenate((np.ones((1, NUM_SAMP))*0, np.ones((1, NUM_SAMP))*1, np.ones((1, NUM_SAMP))*2), axis=None)\n",
    "\n",
    "y_data\n",
    "#nplt.imshow(x_data[290, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have some made up data in x_data, y_data of basic shapes.  Split into test and validation sets and train a simple network\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (10050, 128, 128, 3)\n",
      "10050 train samples\n",
      "4950 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 124, 124, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 58, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 74,275\n",
      "Trainable params: 74,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 10050 samples, validate on 4950 samples\n",
      "Epoch 1/5\n",
      "10050/10050 [==============================] - 11s 1ms/step - loss: 0.9692 - acc: 0.4676 - val_loss: 1.0067 - val_acc: 0.4931\n",
      "Epoch 2/5\n",
      "10050/10050 [==============================] - 11s 1ms/step - loss: 0.6933 - acc: 0.6688 - val_loss: 0.5025 - val_acc: 0.8204\n",
      "Epoch 3/5\n",
      "10050/10050 [==============================] - 11s 1ms/step - loss: 0.2881 - acc: 0.8886 - val_loss: 0.1866 - val_acc: 0.9263\n",
      "Epoch 4/5\n",
      "10050/10050 [==============================] - 11s 1ms/step - loss: 0.1916 - acc: 0.9261 - val_loss: 0.1504 - val_acc: 0.9374\n",
      "Epoch 5/5\n",
      "10050/10050 [==============================] - 11s 1ms/step - loss: 0.1680 - acc: 0.9354 - val_loss: 0.1318 - val_acc: 0.9533\n",
      "Test loss: 0.13181652672664085\n",
      "Test accuracy: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "import pdb\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 3\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = w, h\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))    \n",
    " \n",
    "# let's define the loss function by hand\n",
    "def get_cat_crossentropy_loss():\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        # scale preds so that the class probas of each sample sum to 1\n",
    "        # Don notes: Haven't figured out why this is required.  y_pred is the output of softmax,\n",
    "        # and so should already sum to 1???  Sometimes there is round-off error it looks like and\n",
    "        # it comes out as 0.99999999 or 1.000000002.  I'm not sure why this is a big issue though.\n",
    "        # Practically the algorithm still works and is clipped later.\n",
    "        y_pred_sum = K.print_tensor(tf.reduce_sum(y_pred, -1, True), message=\"y_pred is: \")\n",
    "        y_pred /= y_pred_sum\n",
    "        # manual computation of crossentropy\n",
    "        # Don notes: Looks like any math has to be as a tensor in the same type\n",
    "        _epsilon = tf.convert_to_tensor(K.epsilon(), y_pred.dtype.base_dtype)\n",
    "        # Don notes: We clip the values of y_pred to be away from the asymtopes of the log\n",
    "        # function.  If we didn't, we will get inf or NaN values.\n",
    "        y_pred = tf.clip_by_value(y_pred, _epsilon, 1. - _epsilon)\n",
    "        return - tf.reduce_sum(y_true * tf.log(y_pred), -1)\n",
    "    return weighted_loss\n",
    "    \n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=get_cat_crossentropy_loss(),\n",
    "              optimizer=keras.optimizers.adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21072103131565256\n",
      "0.21072103131565206\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "x=np.array(([0.1, 0.9, 0.4], [0.9, 0.2, 0.3]))\n",
    "\n",
    "y=np.array(([0, 1, 0], [1, 0, 0]))\n",
    "\n",
    "print(np.sum(-np.log(x[y.astype('bool')])))\n",
    "\n",
    "print(np.sum(-np.log(x+sys.float_info.epsilon)*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(x_test)\n",
    "y_prob=model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape.TRIANGLE\n",
      "99.99996423721313%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "class Shape(Enum):\n",
    "    CIRCLE = 0\n",
    "    RECTANGLE = 1\n",
    "    TRIANGLE = 2\n",
    "\n",
    "img_num = random.randint(0, x_test.shape[0])\n",
    "\n",
    "plt.imshow(x_test[img_num, :, :, :])\n",
    "\n",
    "print(Shape(y_pred[img_num]))\n",
    "print((str(y_prob[img_num][y_pred[img_num]]*100) + '%'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caffe2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
