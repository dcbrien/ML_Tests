{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMxdzuylfgLkSha+S63iV0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcbrien/ML_Tests/blob/master/YOLO1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82X2n2KoRqlS"
      },
      "source": [
        "Implementing YOLO v1 as a learning tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAIfgEvORycS"
      },
      "source": [
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import seaborn as sns\n",
        "import glob2\n",
        "\n",
        "from matplotlib.patches import Rectangle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_sKPaHnyKw7",
        "outputId": "f7b9b42d-56c4-4bcd-8f39-1086fc83dc19"
      },
      "source": [
        "# Download VOC challenge 2007\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-10 20:37:37--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M  4.88MB/s    in 91s     \n",
            "\n",
            "2021-08-10 20:39:10 (4.71 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeHuxnENynav"
      },
      "source": [
        "# And unzip\n",
        "!tar -xvf VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "yBjKuy2RRy9q",
        "outputId": "4af99821-347f-468e-ceb7-1454e743e542"
      },
      "source": [
        "# The first thing we will need is a dataset.  Let's make a super simple one where we try to first identify, and second label with bounding\n",
        "# boxes, simple shapes in a relatively small image set.\n",
        "\n",
        "# As an example, here is one image with a circle, square, and triangle\n",
        "IMG_SIZE = (512, 512, 3)\n",
        "\n",
        "img = np.zeros(IMG_SIZE, np.float32)\n",
        "\n",
        "# Circles\n",
        "MIN_C_SIZE = 10\n",
        "MAX_C_SIZE = 100\n",
        "\n",
        "c_size = np.random.randint(low=MIN_C_SIZE, high=MAX_C_SIZE)\n",
        "\n",
        "# We will bound the circle so that it is fully in the image for now - We can try to get it to recognized cropped versions later\n",
        "b_irange = (np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size))\n",
        "print(b_irange)\n",
        "\n",
        "# For each shape we need the bounding box.  This is defined as [x, y, w, h] in the original paper.  For a circle this is simple.\n",
        "bbox = (b_irange[0]-c_size, b_irange[1]-c_size, c_size/IMG_SIZE[0], c_size/IMG_SIZE[1])\n",
        "print(bbox)\n",
        "\n",
        "img2 = cv.circle(img, b_irange, c_size, (np.random.uniform(0, 1), np.random.uniform(0, 1), np.random.uniform(0, 1)), -1)\n",
        "\n",
        "# # Rectangles - 2 points and a colour\n",
        "# r_pt1 = (np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size))\n",
        "# r_pt2 = (np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size))\n",
        "\n",
        "# # For the rectangle, the bounding box is also simple\n",
        "# r_min_x = np.min([r_pt1[0], r_pt2[0]])\n",
        "# r_max_x = np.max([r_pt1[0], r_pt2[0]])\n",
        "# r_min_y = np.min([r_pt1[1], r_pt2[1]])\n",
        "# r_max_y = np.max([r_pt1[1], r_pt2[1]])\n",
        "\n",
        "# bbox = (r_min_x, r_min_y, (r_max_x-r_min_x)/IMG_SIZE[0], (r_max_y-r_min_y)/IMG_SIZE[1])\n",
        "# print(bbox)\n",
        "\n",
        "# img2 = cv.rectangle(img2, r_pt1, r_pt2, (np.random.uniform(0, 1), np.random.uniform(0, 1), np.random.uniform(0, 1)), -1)\n",
        "\n",
        "# # Triangles - 3 points and a colour drawn as a polyfill\n",
        "\n",
        "# pts = np.array([[np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size)],\n",
        "#                 [np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size)],\n",
        "#                 [np.random.randint(low=c_size, high=IMG_SIZE[0]-c_size), np.random.randint(low=c_size, high=IMG_SIZE[1]-c_size)]], np.int32)\n",
        "# pts = pts.reshape((-1,1,2))\n",
        "\n",
        "# # For the triangles, the bounding box is also simple\n",
        "# r_min_x = np.min([pts[0][0][0], pts[1][0][0], pts[2][0][0]])\n",
        "# r_max_x = np.max([pts[0][0][0], pts[1][0][0], pts[2][0][0]])\n",
        "# r_min_y = np.min([pts[0][0][1], pts[1][0][1], pts[2][0][1]])\n",
        "# r_max_y = np.max([pts[0][0][1], pts[1][0][1], pts[2][0][1]])\n",
        "\n",
        "# bbox = (r_min_x, r_min_y, (r_max_x-r_min_x)/IMG_SIZE[0], (r_max_y-r_min_y)/IMG_SIZE[1])\n",
        "# print(bbox)\n",
        "\n",
        "# img2 = cv.fillPoly(img2, [pts], (0,255,255))\n",
        "\n",
        "plt.imshow(img2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(97, 155)\n",
            "(36, 94, 0.119140625, 0.119140625)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff2f80e83d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzBonVNJLUd"
      },
      "source": [
        "# A class to either generate synthetic data or use the VOC challenge 2007 to\n",
        "# generate bounding box data for classification\n",
        "\n",
        "class yoloGenerator():\n",
        "  def __init__(self, num_samp, S, B, img_size=(224, 224, 3), synth=True, batch_size=32):\n",
        "    self.S = S  # Number of subdivisions of grid\n",
        "    self.B = B  # Number of bounding boxes to predict per gric cell\n",
        "    self.num_samp = num_samp\n",
        "    self.img_size = img_size\n",
        "    self.synth = synth\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.G_SIZE = self.img_size[0]//self.S\n",
        "\n",
        "    if synth:\n",
        "      self.C = 3\n",
        "\n",
        "      imgs, labels = self.makeSythData()\n",
        "\n",
        "      self.img_ls = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(imgs), tf.data.Dataset.from_tensor_slices(labels)))   \n",
        "\n",
        "      self.img_ls_b = self.img_ls.batch(self.batch_size,drop_remainder=True)\n",
        "    else:\n",
        "      # TODO: Add code to convert VOC data to a tf.dataset\n",
        "      # VOC has 20 classes\n",
        "      self.C = 20\n",
        "\n",
        "  # Return synethic data of circles, squares, and rectangles  \n",
        "  def makeSythData(self, objs_per_img=3):\n",
        "    # There are many ways to do this, but we don't need that much data so we\n",
        "    # will just create it all in memory as a dataset.  If you had a lot of \n",
        "    # images you would need to stream them from disk.  Just don't make num_samp \n",
        "    # too large (keep it under 10K with a high-ram colab).\n",
        "    # The array holding the raw image data\n",
        "    imgs = np.zeros((self.num_samp, self.img_size[0], self.img_size[1], self.img_size[2]), np.float32)\n",
        "\n",
        "    # The labels are a tensor of (SXSX(4+C)) where the (4+C) is x, y, w, h, \n",
        "    # class. Classes are one-hot.  It will be mostly zeros and there can only \n",
        "    # be one object per grid cell.\n",
        "    labels = np.zeros((self.num_samp, S, S, 4 + self.C), np.float32)\n",
        "\n",
        "    for s in range(self.num_samp):\n",
        "      img = np.zeros(self.img_size, np.float32)\n",
        "\n",
        "      for i in range(objs_per_img):\n",
        "        img_t = np.random.randint(0, 2)\n",
        "\n",
        "        if img_t == 0:\n",
        "          self.addCircle(img, labels, s)\n",
        "        elif img_t == 1:\n",
        "          self.addRectangle(img, labels, s)\n",
        "\n",
        "      imgs[s, :] = img\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "  def addCircle(self, img, labels, s):\n",
        "    # Constansts for circles\n",
        "    MIN_C_SIZE = 20\n",
        "    MAX_C_SIZE = 41\n",
        "    c_size = np.random.randint(low=MIN_C_SIZE, high=MAX_C_SIZE)\n",
        "\n",
        "    # We will bound the circle so that it is fully in the image for now - We can try to get it to recognized cropped versions later\n",
        "    b_irange = (np.random.randint(low=c_size, high=self.img_size[0]-c_size), np.random.randint(low=c_size, high=self.img_size[1]-c_size))\n",
        "    # For each shape we need the bounding box.  This is defined as [x, y, w, h] in the original paper.  For a circle this is simple.\n",
        "    bbox = (b_irange[0]-c_size, b_irange[1]-c_size, c_size*2./self.img_size[0], c_size*2./self.img_size[1])\n",
        "\n",
        "    #Find the grid cell of this object\n",
        "    g_x = b_irange[0] // self.G_SIZE\n",
        "    g_y = b_irange[1] // self.G_SIZE\n",
        "\n",
        "    # We only draw if there is no object in that grid cell already\n",
        "    if np.sum(labels[s, g_x, g_y, 4:]) == 0:\n",
        "      # I bound the colours to make it more realistic.  Most circles will have similar colours, just as most objects in real images will h\n",
        "      # have similar colour profiles\n",
        "      img = cv.circle(img, b_irange, c_size, (np.random.uniform(0.5, 0.7), np.random.uniform(0.5, 0.7), np.random.uniform(0.5, 0.7)), -1)\n",
        "\n",
        "      # Find the relative position\n",
        "      g_xpos = (b_irange[0] % self.G_SIZE) / self.G_SIZE\n",
        "      g_ypos = (b_irange[1] % self.G_SIZE) / self.G_SIZE\n",
        "\n",
        "      # The label - First position is 1 for circles\n",
        "      labels[s, g_x, g_y] = [g_xpos, g_ypos, bbox[2], bbox[3], 1, 0, 0]\n",
        "\n",
        "  def addRectangle(self, img, labels, s):\n",
        "    # Rectangles - 2 points and a colour   \n",
        "\n",
        "    # Constansts for rectangles\n",
        "    MIN_R_SIZE = 20\n",
        "    MAX_R_SIZE = 41\n",
        "    r_size = np.random.randint(low=MIN_R_SIZE, high=MAX_R_SIZE)\n",
        "\n",
        "    r_pt1 = (np.random.randint(low=r_size, high=self.img_size[0]-r_size), np.random.randint(low=r_size, high=self.img_size[1]-r_size))\n",
        "    r_pt2 = (np.random.randint(low=r_size, high=self.img_size[0]-r_size), np.random.randint(low=r_size, high=self.img_size[1]-r_size))\n",
        "\n",
        "    # For the rectangle, the bounding box is also simple\n",
        "    r_min_x = np.min([r_pt1[0], r_pt2[0]])\n",
        "    r_max_x = np.max([r_pt1[0], r_pt2[0]])\n",
        "    r_min_y = np.min([r_pt1[1], r_pt2[1]])\n",
        "    r_max_y = np.max([r_pt1[1], r_pt2[1]])\n",
        "\n",
        "    bbox = ((r_max_x-r_min_x) / 2., (r_max_y-r_min_y) / 2., (r_max_x-r_min_x)/self.img_size[0], (r_max_y-r_min_y)/self.img_size[1])\n",
        "\n",
        "    #Find the grid cell of this object\n",
        "    g_x = (bbox[0] + r_min_x) // self.G_SIZE\n",
        "    g_y = (bbox[1] + r_min_y) // self.G_SIZE\n",
        "\n",
        "    # We only draw if there is no object in that grid cell already and the area of the rectangle is reasonable (0.01 here)\n",
        "    if np.sum(labels[s, int(g_x), int(g_y), 4:]) == 0 and bbox[2] * bbox[3] > 0.01:\n",
        "      img = cv.rectangle(img, r_pt1, r_pt2, (np.random.uniform(0.5, 0.7), np.random.uniform(0.5, 0.7), np.random.uniform(0.5, 0.7)), -1)\n",
        "\n",
        "      # Find the relative position\n",
        "      g_xpos = ((bbox[0] + r_min_x) % self.G_SIZE) / self.G_SIZE\n",
        "      g_ypos = ((bbox[1] + r_min_y) % self.G_SIZE) / self.G_SIZE\n",
        "\n",
        "      # The label - Second position is 1 for circles\n",
        "      labels[s, int(g_x), int(g_y)] = [g_xpos, g_ypos, bbox[2], bbox[3], 0, 1, 0]\n",
        "\n",
        "  def plotImg(self, img, label):\n",
        "    major_ticks = np.arange(self.G_SIZE, self.img_size[0], self.G_SIZE)\n",
        "\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    ax.set_xticks(major_ticks)\n",
        "    ax.set_yticks(major_ticks)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.grid(True)\n",
        "\n",
        "    obs = np.where(np.sum(label[:, :, 4:], axis=-1) > 0)\n",
        "\n",
        "    for s in range(obs[0].shape[0]):\n",
        "      g_x=obs[0][s]\n",
        "      g_y=obs[1][s]\n",
        "\n",
        "      s_label = label[g_x, g_y]\n",
        "\n",
        "      obj_c = (g_x*self.G_SIZE+self.G_SIZE*s_label[0], g_y*self.G_SIZE+self.G_SIZE*s_label[1])\n",
        "\n",
        "      plt.plot(obj_c[0], obj_c[1], 'x')\n",
        "\n",
        "      ax.add_patch(Rectangle((obj_c[0]-(s_label[2]*self.img_size[0])/2., obj_c[1]-s_label[3]*self.img_size[1]/2.), \n",
        "                            s_label[2]*self.img_size[0], s_label[3]*self.img_size[1], color = 'c', alpha=1, fill=False))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6B7P5JIzvGU"
      },
      "source": [
        "NUM_SAMP = 3000\n",
        "S = 7\n",
        "B = 2\n",
        "\n",
        "X_data = yoloGenerator(NUM_SAMP, S, B, img_size=(448, 448, 3), batch_size=16)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "7gOr_uVE1IRV",
        "outputId": "3710ba52-97d6-49f6-afe2-e3aa5159b0ee"
      },
      "source": [
        "# Plot an example\n",
        "for s_samp in X_data.img_ls_b.take(1):\n",
        "  X_data.plotImg(s_samp[0][0, :, :, :], s_samp[1][0, :, :, :])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy9rhU638b5-"
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet101\n",
        "# The model\n",
        "\n",
        "# 1 - Divide image into S x S grid\n",
        "# 2 - For each grid cell, detect an object and predict its bounding box\n",
        "#      - Each grid cell predicts B bounding boxes and confidence scores\n",
        "#      - Confidence = Pr(Object) * IOU{truth/pred}.  This should be 0 when no\n",
        "#        Object is present and the IOU when one is present\n",
        "#      - Each bounding box predicts x, y, w, h and C, where x, y is the center\n",
        "#        prediction of the bounding box relative to the bounds of the grid cell\n",
        "#        (percentage of grid cell size) and w, h are predicted relative to the \n",
        "#        entire image (percentages).  I think it makes the loss function \n",
        "#        simpler to have all values between 0 and 1.  It also normalizes the \n",
        "#        values so they all have equal weight in the loss function.\n",
        "# 3 - Each grid cell predicts C conditional class probabilities\n",
        "#   Pr(Class(i)|Object).  If the grid contains an object, it predicts a class. \n",
        "#   This is only done once per grid cell, regardless of the number of bounding \n",
        "#   boxes B.  It does seem like this could be a softmax instead, but they are \n",
        "#   just predicting independent probabilities and using MSE to calculate the \n",
        "#   loss.\n",
        "#      - At test time, we can therefore multiple Pr(Class(i)|Object) * \n",
        "#        Pr(Object) * IOU{truth/pred} = Pr(Class(i)) * IOU{truth/pred}.  Which \n",
        "#        are class specific confidence sscores for each bounding box. \n",
        "#        IOU{truth/pred} are probabilities as well as they are bounded [0, 1]\n",
        "\n",
        "# The output of the model should be a tensor of size S * S * (B * 5 + C).  This \n",
        "# 5 values per bounding box + C class probabilites all per grid cell\n",
        "\n",
        "# The model is super simple.  Use some kind of convolution network to extract \n",
        "# the features and use a FCN top level to generate the prediction tensor.  I \n",
        "# think just a pre-trained ResNet with some extra convolution layers and a FCN \n",
        "# top layer should work reasonably well.  The last layer has no activation \n",
        "# function to allow it to predict the complete range of bounding box and \n",
        "# confidence intervals without asymptotes.\n",
        "\n",
        "class YOLOv1(tf.keras.Model):\n",
        "  def __init__(self, S, B, num_classes, img_size, rate=0.5):\n",
        "    super(YOLOv1, self).__init__()\n",
        "\n",
        "    # The output tensor - See Figure 2 of the paper and the paragraph just\n",
        "    # underneath\n",
        "    self.S = S\n",
        "    self.B = B\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    self.rate = rate\n",
        "\n",
        "    self.output_size = (S*S*(B*5+num_classes))\n",
        "\n",
        "    # TODO: Data augmentation should go here, but will have to also adjust the \n",
        "    # bounding boxes in that case?  I don't think I will implement it for this \n",
        "    # little test case, but that would certainly be necessary for a robust \n",
        "    # object segmentation model\n",
        "\n",
        "    # The hybrid model includes a partial ResNet as a prenet.  I cut it off at \n",
        "    # layer 3 and allow that last layer to still be trainable.  This scales \n",
        "    # everything down for cifar-10.\n",
        "    base_model = ResNet101(weights='imagenet', include_top=False, pooling='avg', input_shape=(img_size[0], img_size[1], 3))\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "    #for layer in base_model.layers[39:]:\n",
        "    #  layer.trainable = True\n",
        "\n",
        "    self.prenet = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer('conv2_block2_out').output)\n",
        "\n",
        "    #self.tokenizer = tf.keras.layers.Conv2D(filters=d_model, kernel_size=1, strides=1, padding='valid')\n",
        "\n",
        "    #self.glob_avg = tf.keras.layers.GlobalAveragePooling1D()\n",
        "\n",
        "    # These layers will just bring us down to a 7x7 matrix from the original\n",
        "    # ResNet.  We could make this more generic though.  It doesn't have to be \n",
        "    # so complicated\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=512, kernel_size=1, strides=1, padding='valid')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, strides=2, padding='same')\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, strides=2, padding='same')\n",
        "    self.conv4 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, strides=2, padding='same') \n",
        "    self.conv5 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, strides=2, padding='same')\n",
        "\n",
        "    # Now a FCN to allow some cross talk between features (I think it's\n",
        "    # important to have this layer in here and not just continue to reduce \n",
        "    # down to output tensor.  This layer allows a higher level of complexity \n",
        "    # and capacity in the output space.)\n",
        "\n",
        "    # We use 4096 just like the paper\n",
        "    self.int_layer = tf.keras.layers.Dense(4096, activation=tf.keras.layers.LeakyReLU(alpha=0.01), name='intlayer')\n",
        "\n",
        "    self.d1 = tf.keras.layers.Dropout(self.rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(self.output_size, activation='linear', name='classes')\n",
        "\n",
        "  def call(self, inp, training):\n",
        "    x = self.prenet(inp)\n",
        "\n",
        "    # Not the exact architecture of the paper, but we will apply some \n",
        "    # convolutions after the ResNet to be somewhat consistent\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)    \n",
        "    x = self.conv5(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    x = self.int_layer(x)\n",
        "\n",
        "    x = self.d1(x)\n",
        "\n",
        "    final_output = self.final_layer(x)\n",
        "\n",
        "    # Reshape to the output tensor\n",
        "    final_output = tf.reshape(final_output, [-1, self.S, self.S, self.B*5+self.num_classes])\n",
        "\n",
        "    return final_output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZgRk2oN77H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45e5672-ff08-41cf-e674-656540193e06"
      },
      "source": [
        "# Let's test out YOLOv1 on a simple example first\n",
        "dropout_rate = 0.5\n",
        "\n",
        "yolo_model = YOLOv1(X_data.S, X_data.B, X_data.C, X_data.img_size, dropout_rate)\n",
        "\n",
        "byte_samp = tf.random.normal((2, X_data.img_size[0], X_data.img_size[1], 3))\n",
        "\n",
        "y_pred = yolo_model(byte_samp, True)\n",
        "\n",
        "y_pred.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171450368/171446536 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 7, 7, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7-0OuFqlWWW"
      },
      "source": [
        "# The loss function\n",
        "# Inputs will be ypred, ytruth (a ragged tensor containing bounding boxes \n",
        "# and corresponding class value so Nx5 array, where the are N bounding boxes)\n",
        "\n",
        "# ypred has 3D shape SxSx(B*5+C)\n",
        "\n",
        "# lambda_coord = regularization parameter to weight coordinates heavily when an\n",
        "# object is present\n",
        "\n",
        "# lambda_noobj = regularization parameter to weight IOU predictions less when \n",
        "# no object is present so that the network doesn't immediately predict zero \n",
        "# confidence for every grid cell and promotes better training\n",
        "\n",
        "# for every grid cell in SxS\n",
        "#   Split ypred at this grid cell location into B*5 values and C values\n",
        "#   If there an object in this grid\n",
        "#     Compute x_truth, y_truth in relative coordinates to the grid cell bounds\n",
        "#     Compute IOU for each B - This is C_truth - Computed by creating a mask \n",
        "#       for the original bounding box and a mask for each predicted B and then \n",
        "#       logically comparing them\n",
        "#     for the max IOU\n",
        "#       loss = lambda_coord * MSE in x\n",
        "#       loss += lambda_coord * MSE in sqrt(w) + MSE in sqrt(h)\n",
        "#       loss += SE in IOU\n",
        "#       loss += SE in class probabilities for each class\n",
        "#   else\n",
        "#     loss = lambda_noobj * SE in IOU (IOU_truth is 0 when no object) - we want \n",
        "#       these all to go to zero so we can threshold them out later in the \n",
        "#       testing phase\n",
        "\n",
        "# We can't use flow control statements in the loss function so we will need\n",
        "# to be creative to vectorize this\n",
        "# The target tensor will be SxSx5 for each image so we can create object and\n",
        "# no object masks to create the loss function in a vectorized form and not \n",
        "# require for loops and if statements\n",
        "\n",
        "EPS = 0.0000001\n",
        "\n",
        "LAMBDA_COORD = 5.\n",
        "LAMBDA_NOOBJ = 0.5\n",
        "\n",
        "B = X_data.B\n",
        "C = X_data.C\n",
        "\n",
        "def my_loss_fun_YOLOv1(y_true, y_pred):\n",
        "  # y_true has shape SxSx(4+C) - the 4 numbers are x, y, w, h and the C should \n",
        "  # be a probability array of the number of classes I think\n",
        "  # y_pred has shape SxSx(B*5+C) - The same 4 numbers * B bounding boxes with \n",
        "  # the confidence score being the 5th here.  C is also the probability of each\n",
        "  # class\n",
        "\n",
        "  # The first thing we need is to know the IOU of each B when a cell has an\n",
        "  # object\n",
        "\n",
        "  # Tile the values in y_true so we can broadcast compute every IOU in the grid\n",
        "  # at once\n",
        "  y_true_all = y_true[:, :, :, :4]\n",
        "  y_true_bbox = tf.tile(y_true_all, [1,1,1, B])\n",
        "  y_true_bbox = tf.reshape(y_true_bbox, [-1, S, S, B, 4])\n",
        "\n",
        "  # I really think, if the model has no activation function in the last layer,\n",
        "  # that we have to exp the result to get values only between 0 and 1.  I \n",
        "  # verified this with a Google search.\n",
        "  y_pred = tf.exp(y_pred)\n",
        "\n",
        "  y_pred = tf.clip_by_value(y_pred, EPS, np.inf)\n",
        "\n",
        "  # y_pred should match\n",
        "  y_pred_all = y_pred[:, :, :, :B*5]\n",
        "  y_pred_all = tf.reshape(y_pred_all, [-1, S, S, B, 5])\n",
        "  y_pred_all = y_pred_all[:, :, :, :, :5]\n",
        "\n",
        "  y_pred_bbox = y_pred_all[:, :, :, :, :4]\n",
        "\n",
        "  # now compute IOU of every grid cell (even though we will only end up using\n",
        "  # the ones where an object is present?)  The IOU of all non-object grid cells \n",
        "  # must be zero because the intersection of a bounding box with an empty set \n",
        "  # is empty.\n",
        "\n",
        "  # first convert them all to proper bounding boxes [x1, y1, x2, y2]\n",
        "  bbox1 = tf.stack([y_pred_bbox[:, :, :, :, 0] - y_pred_bbox[:, :, :, :, 2] / 2., \n",
        "          y_pred_bbox[:, :, :, :, 1] - y_pred_bbox[:, :, :, :, 3] / 2.,\n",
        "          y_pred_bbox[:, :, :, :, 0] + y_pred_bbox[:, :, :, :, 2] / 2.,\n",
        "          y_pred_bbox[:, :, :, :, 1] + y_pred_bbox[:, :, :, :, 3] / 2.], axis=-1)\n",
        "\n",
        "  bbox2 = tf.stack([y_true_bbox[:, :, :, :, 0] - y_true_bbox[:, :, :, :, 2] / 2., \n",
        "          y_true_bbox[:, :, :, :, 1] - y_true_bbox[:, :, :, :, 3] / 2.,\n",
        "          y_true_bbox[:, :, :, :, 0] + y_true_bbox[:, :, :, :, 2] / 2.,\n",
        "          y_true_bbox[:, :, :, :, 1] + y_true_bbox[:, :, :, :, 3] / 2.], axis=-1)          \n",
        "\n",
        "  xI1 = tf.maximum(bbox1[:, :, :, :, 0], bbox2[:, :, :, :, 0])\n",
        "  yI1 = tf.maximum(bbox1[:, :, :, :, 1], bbox2[:, :, :, :, 1])\n",
        "  xI2 = tf.minimum(bbox1[:, :, :, :, 2], bbox2[:, :, :, :, 2])\n",
        "  yI2 = tf.minimum(bbox1[:, :, :, :, 3], bbox2[:, :, :, :, 3])\n",
        "\n",
        "  # The intersection of the two bounding boxes.  The + 1. is because of the \n",
        "  # pixel space including both extremes\n",
        "  AoI = tf.maximum(0., xI2 - xI1 + 1.) * tf.maximum(0., yI2 - yI1 + 1.)\n",
        "\n",
        "  # Now calculate the areas of each bbox\n",
        "  Abbox1 = (bbox1[:, :, :, :, 2] - bbox1[:, :, :, :, 0] + 1.) * (bbox1[:, :, :, :, 3] - bbox1[:, :, :, :, 1] + 1.)\n",
        "  Abbox2 = (bbox2[:, :, :, :, 2] - bbox2[:, :, :, :, 0] + 1.) * (bbox2[:, :, :, :, 3] - bbox2[:, :, :, :, 1] + 1.)\n",
        "\n",
        "  IoU = AoI / (Abbox1 + Abbox2 - AoI)\n",
        "\n",
        "  # We will need the best IoU later\n",
        "  best_IoU = tf.math.reduce_max(IoU, -1)\n",
        "\n",
        "  IoU = tf.expand_dims(IoU, -1)\n",
        "\n",
        "\n",
        "  # We want to know the max bounding box for each IoU - this one is responsible \n",
        "  # for prediction in that grid cell\n",
        "  IoU_resp = tf.argsort(IoU, axis=-2, direction='DESCENDING')\n",
        "\n",
        "  # This is super complicated in tensorflow, but to get the last dimension of\n",
        "  # values intact, we treat the batches and grid as a batch dimensions and\n",
        "  # sort on the next to last dimension.  Now the box paramaters in the last\n",
        "  # dimension will be sorted by IoU value.\n",
        "  y_pred_best = tf.gather_nd(y_pred_all, IoU_resp, batch_dims=3)\n",
        "  y_pred_best = y_pred_best[:, :, :, 0, :]\n",
        "\n",
        "  # y_pred_best now contains the 5 values for the highest IOU in each grid cell\n",
        "  # Now we can start to compile the 5 part loss\n",
        "\n",
        "  # We need to know which cells have objects as well.  This is true if any of \n",
        "  # C are 1\n",
        "  obj_mask = tf.where(tf.reduce_sum(y_true[:, :, :, 4:], -1) > 0, 1., 0.)\n",
        "  nobj_mask = 1. - obj_mask\n",
        "\n",
        "  # the position\n",
        "  loss1 = tf.pow((y_true[:, :, :, 0] - y_pred_best[:, :, :, 0]), 2) + tf.pow((y_true[:, :, :, 1] - y_pred_best[:, :, :, 1]), 2)\n",
        "  #print(loss1.shape)\n",
        "  loss1 = tf.reduce_sum(tf.reduce_sum(loss1 * obj_mask, -1), -1)\n",
        "\n",
        "  # the width and height\n",
        "  loss2 = tf.pow((tf.sqrt(y_true[:, :, :, 2]) - tf.sqrt(y_pred_best[:, :, :, 2])), 2) + tf.pow((tf.sqrt(y_true[:, :, :, 3]) - tf.sqrt(y_pred_best[:, :, :, 3])), 2)\n",
        "  loss2 = tf.reduce_sum(tf.reduce_sum(loss2 * obj_mask, -1), -1)\n",
        "\n",
        "  # the Confidence in objects - This isn't super clear in the paper. They say\n",
        "  # that the confidence score should equal the IOU of the best prediction.  I \n",
        "  # have seen it implemented as a 1 or 0 though as well to predict the\n",
        "  # existence of an object.  I think it should be compared to the true IOU \n",
        "  # though, as in the paper, as we want it to reflect real confidence, which \n",
        "  # will increase as IOU increases, and IOU will only increase if the previous\n",
        "  # 2 losses converge on the real box as well.\n",
        "  loss3 = tf.pow((best_IoU - y_pred_best[:, :, :, 4]),  2)\n",
        "  loss3 = tf.reduce_sum(tf.reduce_sum(loss3 * obj_mask, -1), -1)\n",
        "  \n",
        "  # The Confidence in non-objects.  I assume this should just be 0.  There is \n",
        "  # no point in comparing to the true label because that value is 0.  We want\n",
        "  # the last value of y_pred_best to be 0 basically.  The IoU of all of those \n",
        "  # scores should be zero, because there is no true box.  Because of the way \n",
        "  # IoU is calculated, if it's one pixel, we can can still get a IoU score,\n",
        "  # even though it doesn't exist (i.e., when the true box is 0,0,0,0, that is \n",
        "  # assumed to be one pixel and has an area of 1, but we will just make that \n",
        "  # zero for the purposes of this loss)\n",
        "  loss4 = tf.pow((y_pred_best[:, :, :, 4]), 2)\n",
        "  loss4 = tf.reduce_sum(tf.reduce_sum(loss4 * nobj_mask, -1), -1)\n",
        "\n",
        "  # The class loss.  Here we assume the true values will be tacked onto the \n",
        "  # end as y_true[:, :, :, 4:] with one-hot for the value of the object in that \n",
        "  # grid cell.  The prediction will also then be one-hot in the prediction \n",
        "  # array.  For now we only have one class (circles)\n",
        "  loss5 = tf.pow((y_true[:, :, :, 4:] - y_pred[:, :, :, B*5:]), 2)\n",
        "\n",
        "  loss5 = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(loss5, -1)  * obj_mask, -1), -1)\n",
        "  \n",
        "  tot_loss = LAMBDA_COORD * loss1 + LAMBDA_COORD * loss2 + loss3 + LAMBDA_NOOBJ * loss4 + loss5\n",
        "\n",
        "  return(tot_loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9DNLch1G0tE",
        "outputId": "db63102f-9884-4e82-e871-5fb54697ca4b"
      },
      "source": [
        "# Test out the loss function\n",
        "# y_true will be our labels we created\n",
        "\n",
        "y_true = s_samp[1][:2, :]\n",
        "\n",
        "y_pred_test = tf.random.normal((2, S, S, B*5+X_data.C), 0,)\n",
        "\n",
        "my_loss_fun_YOLOv1(y_true, y_pred_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([422.54977, 223.20264], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wHuy-kaEPnu"
      },
      "source": [
        "X_train = X_data.img_ls_b.take(round(NUM_SAMP/X_data.batch_size*0.90)) \n",
        "X_test = X_data.img_ls_b.skip(round(NUM_SAMP/X_data.batch_size*0.10))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfxIolElSA_P"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch <= 75:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5yWNV-m8KM8P",
        "outputId": "b5ec974e-bbef-420c-a0ae-6e556b9d7241"
      },
      "source": [
        "# Now we can train.\n",
        "# TODO: Create a custom MAP metric when we have multiple classes\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "learning_rate = 0.00001\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "#optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "yolo_model.compile(optimizer=optimizer, loss=my_loss_fun_YOLOv1)\n",
        "history = yolo_model.fit(X_train.prefetch(tf.data.experimental.AUTOTUNE), validation_data=X_test.prefetch(tf.data.experimental.AUTOTUNE), epochs=100, verbose=1, callbacks=[callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "169/169 [==============================] - 126s 707ms/step - loss: 103.8018 - val_loss: 8.8837\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - 119s 706ms/step - loss: 19.1579 - val_loss: 6.5986\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 20.2860 - val_loss: 6.1568\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 12.6024 - val_loss: 5.7673\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - 121s 716ms/step - loss: 9.7192 - val_loss: 5.1428\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - 119s 705ms/step - loss: 8.4054 - val_loss: 4.8647\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 7.1393 - val_loss: 4.4057\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 6.6635 - val_loss: 4.0957\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 5.9335 - val_loss: 4.0906\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 5.9297 - val_loss: 3.6465\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 5.3272 - val_loss: 3.5701\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - 119s 702ms/step - loss: 4.9394 - val_loss: 3.3203\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 4.6362 - val_loss: 3.3222\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 4.2436 - val_loss: 3.1355\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 4.2150 - val_loss: 3.0030\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 3.9686 - val_loss: 2.9381\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - 119s 705ms/step - loss: 3.8604 - val_loss: 2.8234\n",
            "Epoch 18/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 3.6382 - val_loss: 2.8378\n",
            "Epoch 19/100\n",
            "169/169 [==============================] - 118s 702ms/step - loss: 3.6401 - val_loss: 2.7325\n",
            "Epoch 20/100\n",
            "169/169 [==============================] - 119s 705ms/step - loss: 3.4479 - val_loss: 2.6216\n",
            "Epoch 21/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 3.3738 - val_loss: 2.6557\n",
            "Epoch 22/100\n",
            "169/169 [==============================] - 119s 702ms/step - loss: 3.2721 - val_loss: 2.5183\n",
            "Epoch 23/100\n",
            "169/169 [==============================] - 119s 703ms/step - loss: 3.1406 - val_loss: 2.4503\n",
            "Epoch 24/100\n",
            "169/169 [==============================] - 119s 704ms/step - loss: 3.0701 - val_loss: 2.4072\n",
            "Epoch 25/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 2.9695 - val_loss: 2.2898\n",
            "Epoch 26/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.9161 - val_loss: 2.3066\n",
            "Epoch 27/100\n",
            "169/169 [==============================] - 125s 739ms/step - loss: 2.8519 - val_loss: 2.2097\n",
            "Epoch 28/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.7341 - val_loss: 2.1640\n",
            "Epoch 29/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.6787 - val_loss: 2.1605\n",
            "Epoch 30/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.6073 - val_loss: 2.0588\n",
            "Epoch 31/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.5558 - val_loss: 2.0544\n",
            "Epoch 32/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.4923 - val_loss: 1.9740\n",
            "Epoch 33/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.4476 - val_loss: 2.0172\n",
            "Epoch 34/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.4060 - val_loss: 2.0035\n",
            "Epoch 35/100\n",
            "169/169 [==============================] - 125s 743ms/step - loss: 2.3712 - val_loss: 1.9102\n",
            "Epoch 36/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.3259 - val_loss: 1.8676\n",
            "Epoch 37/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 2.2795 - val_loss: 1.8514\n",
            "Epoch 38/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.2065 - val_loss: 1.8127\n",
            "Epoch 39/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 2.1895 - val_loss: 1.8056\n",
            "Epoch 40/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 2.1566 - val_loss: 1.8301\n",
            "Epoch 41/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 2.1187 - val_loss: 1.7858\n",
            "Epoch 42/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.0833 - val_loss: 1.7358\n",
            "Epoch 43/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 2.0546 - val_loss: 1.7795\n",
            "Epoch 44/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 2.0349 - val_loss: 1.6350\n",
            "Epoch 45/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.9998 - val_loss: 1.6645\n",
            "Epoch 46/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.9744 - val_loss: 1.6267\n",
            "Epoch 47/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.9518 - val_loss: 1.6089\n",
            "Epoch 48/100\n",
            "169/169 [==============================] - 125s 739ms/step - loss: 1.9240 - val_loss: 1.5321\n",
            "Epoch 49/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.8896 - val_loss: 1.5967\n",
            "Epoch 50/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.8681 - val_loss: 1.4836\n",
            "Epoch 51/100\n",
            "169/169 [==============================] - 125s 738ms/step - loss: 1.8661 - val_loss: 1.5057\n",
            "Epoch 52/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 1.8341 - val_loss: 1.4710\n",
            "Epoch 53/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.7867 - val_loss: 1.4721\n",
            "Epoch 54/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 1.7926 - val_loss: 1.4526\n",
            "Epoch 55/100\n",
            "169/169 [==============================] - 125s 742ms/step - loss: 1.7453 - val_loss: 1.4026\n",
            "Epoch 56/100\n",
            "169/169 [==============================] - 125s 741ms/step - loss: 1.7400 - val_loss: 1.4103\n",
            "Epoch 57/100\n",
            "169/169 [==============================] - 125s 740ms/step - loss: 1.7283 - val_loss: 1.4570\n",
            "Epoch 58/100\n",
            " 60/169 [=========>....................] - ETA: 56s - loss: 1.7302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fbe7f2e24543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_loss_fun_YOLOv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9OHzmfHyX8g5",
        "outputId": "f2a44928-e229-42f0-f35e-5b58e7ce6548"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['loss'][2:])\n",
        "plt.plot(history.history['val_loss'][2:])\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "lWZnRBC9H0By",
        "outputId": "b65b56a5-3a73-4226-e1f4-5b4c5ca655ab"
      },
      "source": [
        "# Plot an example\n",
        "\n",
        "# Must be less than batch size\n",
        "IMG_NUM = 5\n",
        "\n",
        "# We will just shuffle the test set and take a batch sample.  Then we plot some \n",
        "# heat maps of the predicted IOUs and plot the best bounding boxes.\n",
        "for s_samp in X_test.shuffle(256).take(1):\n",
        "  y_pred=yolo_model.predict(s_samp[0])\n",
        "  y = tf.exp(y_pred[IMG_NUM, :, :, :]).numpy()\n",
        "\n",
        "  plt.imshow(y[:,:,4].T)\n",
        "  plt.figure()\n",
        "  plt.imshow(y[:,:,9].T)\n",
        "\n",
        "  y_ind = np.logical_or(y[:,:,4] < 0.3, np.logical_and(y[:,:,10] < 0.5, y[:,:,11] < 0.5))\n",
        "\n",
        "  y[y_ind, :] = np.zeros((np.sum(y_ind), 13))  \n",
        "\n",
        "  X_data.plotImg(s_samp[0][IMG_NUM, :, :, :], np.concatenate((y[:, :, :4], y[:, :, B*5:]), -1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALfUlEQVR4nO3d/4tldR3H8ddrxll3XbfdQhNzlzSwIIIylpVQogxjS8l+CFJIKIL9pUIpiOqX8B8Q+6GCRS1DTSITRMySMkxIc9e2/LIWIoa7WGNf1N0td3ZnXv0wR5q1HefMnXvOubx7PmDYe2eu5/0extf9nHvuPeftJAJQx9TQDQAYL0INFEOogWIINVAMoQaKOaWLja7zqVmvjV1sekWenh6kriRpasDnyCkPV1tS5o4NVtse7nfPwsIgdV/VEc3l6El/8U5CvV4bdaE/0sWmVzS9+c2D1JUkn7ZhsNo6dd1wtSXNH3xhsNpDPpEv/Otfg9R9JL9Y9mfsfgPFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0U0yrUtnfa/qPtZ2x/reumAIxuxVDbnpb0bUkfk/RuSVfZfnfXjQEYTZuVeoekZ5I8m2RO0h2Srui2LQCjahPqcyQ9v+T+geZ7J7C9y/Ye23uO6ei4+gOwSmM7UJZkd5LtSbbP6NRxbRbAKrUJ9UFJ25bc39p8D8AEahPqRyWdb/s82+skXSnp7m7bAjCqFS9nlOS47S9K+pmkaUk3J3my884AjKTVNcqS3Cvp3o57ATAGfKIMKIZQA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxhBooppOpl143o1Petm3lB3Ygp582SF1JWpgZbvri/IaZwWpL0kwyXPFjxwcrPfXmLYPU9V+X/3uzUgPFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYtpMvbzZ9qztJ/poCMDatFmpvy9pZ8d9ABiTFUOd5EFJ/+ihFwBjMLbzqW3vkrRLktZPbxrXZgGsUiejbNdNbxjXZgGsEke/gWIINVBMm7e0fijpN5LeZfuA7c933xaAUbWZT31VH40AGA92v4FiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWI6GWWr+QXllcOdbHpFA46yffWs4Wof3dLNn7KtN80NN07W88ON0Z16+cgwhe1lf8RKDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWIINVAMoQaKaXPd7222H7D9lO0nbV/TR2MARtPm1J7jkr6S5DHbmyTttX1/kqc67g3ACNqMsn0hyWPN7UOS9ks6p+vGAIxmVSfh2j5X0gWSHjnJz/47ynbq9DG0BmAUrQ+U2T5d0p2Srk3yyut/fsIoW68fZ48AVqFVqG3PaDHQtyX5SbctAViLNke/LekmSfuTXN99SwDWos1KfZGkqyVdYntf8/XxjvsCMKI2o2wfkrT8Vc4ATBQ+UQYUQ6iBYgg1UAyhBooh1EAxhBoohlADxRBqoBhCDRTTzfzTRJmb62TTK5beMDNIXUma2zzcONkXr3h1sNqSdGjf5sFqP37tdwarfdmFlw9UefnxvazUQDGEGiiGUAPFEGqgGEINFEOogWIINVAMoQaKIdRAMYQaKIZQA8UQaqCYNhfzX2/7t7Z/34yyva6PxgCMps1pRUclXZLkcDN+5yHbP03ycMe9ARhBm4v5R9Lh5u5M87X8eV8ABtV2QN607X2SZiXdn+Sko2xt77G9Zy7DntsL/D9rFeok80neJ2mrpB2233OSxzDKFpgAqzr6neQlSQ9I2tlNOwDWqs3R7zNtb2lub5B0qaSnu24MwGjaHP0+W9Ittqe1+CTwoyT3dNsWgFG1Ofr9B0kX9NALgDHgE2VAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxhBooppuBylOWNwxz+uXU3w8NUleSThtwNvY7bpgfrLYkvfzOhcFqX/rpzw1We2bTkWEKzy6/HrNSA8UQaqAYQg0UQ6iBYgg1UAyhBooh1EAxhBoohlADxRBqoBhCDRTTOtTNPK3f2eaa38AEW81KfY2k/V01AmA82k693CrpMkk3dtsOgLVqu1LfIOmrkpY9v+6EUbYLjLIFhtJmQN7lkmaT7H2jx50wynaKUbbAUNqs1BdJ+oTt5yTdIekS27d22hWAka0Y6iRfT7I1ybmSrpT0yySf6bwzACPhfWqgmFVdoyzJryT9qpNOAIwFKzVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWIINVAMoQaK6WaU7YAWNm8crPb04bnBamvaw9WW9JaH/zpc8XXDjRDWi/8cpu7x5UcXs1IDxRBqoBhCDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFNPqs9/NdI5DkuYlHU+yvcumAIxuNSd0fDjJ3zrrBMBYsPsNFNM21JH0c9t7be862QMYZQtMhra73xcnOWj7rZLut/10kgeXPiDJbkm7JWnzzJkZc58AWmq1Uic52Pw7K+kuSTu6bArA6NoMnd9oe9NrtyV9VNITXTcGYDRtdr/PknSX7dcef3uS+zrtCsDIVgx1kmclvbeHXgCMAW9pAcUQaqAYQg0UQ6iBYgg1UAyhBooh1EAxhBoohlADxRBqoJhORtlmfl4LL73cxaZXNOXhnqemNm4YrHaO/Huw2pKkheVHq3burDOGq31soPHFWf7sZlZqoBhCDRRDqIFiCDVQDKEGiiHUQDGEGiiGUAPFEGqgGEINFEOogWJahdr2Fts/tv207f22P9B1YwBG0/aEjm9Jui/Jp2yvk3Rahz0BWIMVQ217s6QPSvqsJCWZkzTQqSkAVtJm9/s8SS9K+p7t39m+sZmpdYKlo2yP5ejYGwXQTptQnyLp/ZK+m+QCSUckfe31D0qyO8n2JNtnfOqY2wTQVptQH5B0IMkjzf0fazHkACbQiqFO8hdJz9t+V/Otj0h6qtOuAIys7dHvL0m6rTny/aykz3XXEoC1aBXqJPskbe+4FwBjwCfKgGIINVAMoQaKIdRAMYQaKIZQA8UQaqAYQg0UQ6iBYgg1UIzzBiMxR96o/aKkP4/4n58h6W9jbIfa1K5Y++1JzjzZDzoJ9VrY3pNkkM+ZU5vaFWqz+w0UQ6iBYiYx1LupTW1qj27iXlMDWJtJXKkBrAGhBoqZqFDb3mn7j7afsf0/lyHusO7NtmdtP9FXzSW1t9l+wPZTtp+0fU2Ptdfb/q3t3ze1r+ur9pIeppvryd/Tc93nbD9ue5/tPT3X7nSM1cS8prY9LelPki7V4mWJH5V0VZLOr1xq+4OSDkv6QZL3dF3vdbXPlnR2ksdsb5K0V9Ine/q9LWljksO2ZyQ9JOmaJA93XXtJD1/W4vXv3pTk8h7rPidpe5LeP3xi+xZJv05y42tjrJK8NK7tT9JKvUPSM0mebUb73CHpij4KJ3lQ0j/6qHWS2i8keay5fUjSfknn9FQ7SQ43d2ear96e5W1vlXSZpBv7qjm0JWOsbpIWx1iNM9DSZIX6HEnPL7l/QD39zz0pbJ8r6QJJj7zxI8dac9r2Pkmzku5fMrShDzdI+qqkhR5rviaSfm57r+1dPdZtNcZqLSYp1P/XbJ8u6U5J1yZ5pa+6SeaTvE/SVkk7bPfy8sP25ZJmk+zto95JXJzk/ZI+JukLzUuwPrQaY7UWkxTqg5K2Lbm/tfleec3r2Tsl3ZbkJ0P00OwCPiBpZ08lL5L0iea17R2SLrF9a0+1leRg8++spLu0+PKvD52PsZqkUD8q6Xzb5zUHD66UdPfAPXWuOVh1k6T9Sa7vufaZtrc0tzdo8SDl033UTvL1JFuTnKvFv/Uvk3ymj9q2NzYHJdXs+n5UUi/vfPQxxqrt2J3OJTlu+4uSfiZpWtLNSZ7so7btH0r6kKQzbB+Q9M0kN/VRW4sr1tWSHm9e20rSN5Lc20PtsyXd0rzzMCXpR0l6fWtpIGdJumvx+VSnSLo9yX091u90jNXEvKUFYDwmafcbwBgQaqAYQg0UQ6iBYgg1UAyhBooh1EAx/wHcrfcqnpJ+fwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}