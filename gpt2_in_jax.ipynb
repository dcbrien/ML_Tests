{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import flax\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d75852054eb40a88b4af9538d7d8e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c4f3e93bab40199e54724371970541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flax_model.msgpack:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0ea9700eb241f3a336beb4e83cfdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import FlaxGPT2LMHeadModel\n",
    "\n",
    "model_hf = FlaxGPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized parameter shapes:\n",
      " {'transformer': {'h': {'0': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '1': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '10': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '11': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '2': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '3': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '4': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '5': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '6': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '7': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '8': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '9': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}}, 'ln_f': {'bias': (768,), 'scale': (768,)}, 'wpe': {'embedding': (1024, 768)}, 'wte': {'embedding': (50257, 768)}}}\n"
     ]
    }
   ],
   "source": [
    "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(model_hf.params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.shape(model_hf.params['transformer']['wpe']['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['c_attn', 'c_proj'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf.params['transformer']['h']['0']['attn'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "from functools import partial\n",
    "\n",
    "# define a full GTP2 class in Flax and see if we can replicate the original paper along with\n",
    "# Karpathy\n",
    "\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50257\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "\n",
    "class GPTMLP(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    def setup(self):\n",
    "        # Simple MLP that upscales, runs through a gelu activation,\n",
    "        # and then resamples back to the n_embd size (the model size)\n",
    "        #self.c_fc = nn.Dense(4 * self.config.n_embd)\n",
    "        # Had to use Einsum to match the matrix multiplication of GPT2 and pytorch. They accept \n",
    "        # both shapes and then multiply by the transpose of the matrix (basically means the \n",
    "        # shape of the matrix is transpose, but the operation is the same)\n",
    "        self.c_fc = nn.Einsum((4 * self.config.n_embd, self.config.n_embd), '...ij,...kj->...ik')\n",
    "        #self.c_proj = nn.Dense(self.config.n_embd)\n",
    "        self.c_proj = nn.Einsum((self.config.n_embd, 4 * self.config.n_embd), '...ij,...kj->...ik')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "\n",
    "        x = self.c_fc(x)\n",
    "        x = nn.gelu(x, approximate=True)\n",
    "        x = self.c_proj(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class GPTAttention(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    # we will need to roll our own attention module because the built in one has a bunch of different\n",
    "    # naming and structure compared to the original GPT, which just references the projection layers\n",
    "    def setup(self):\n",
    "        # The first thing we do is project up to 3x the model size, because we are going to split\n",
    "        # the data into q, v, k\n",
    "        self.c_attn = nn.Einsum((3 * self.config.n_embd, self.config.n_embd), '...ij,...kj->...ik')\n",
    "\n",
    "        # At the end we have to project everything back to the regular model size of n_embd\n",
    "        self.c_proj = nn.Einsum((self.config.n_embd, self.config.n_embd), '...ij,...kj->...ik')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        B, T, C = jnp.shape(x)\n",
    "        \n",
    "        # Project to qkv\n",
    "        qkv = self.c_attn(x)\n",
    "\n",
    "        q, k, v = jnp.split(qkv, 3, axis=2)\n",
    "\n",
    "        query_length, key_length = q.shape[1], k.shape[1]\n",
    "\n",
    "        # Now reshape with a new head \"batch\" dimension\n",
    "        k = jnp.reshape(k, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "        q = jnp.reshape(q, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "        v = jnp.reshape(v, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "\n",
    "        # Make the attention mask\n",
    "        # TODO: For round 1 I'm just trusting the linen functions. They seem to be doing the correct thing here, but I may have to \n",
    "        # return to this for a closer look at the math if I'm not getting the GPT2 results\n",
    "        c_mask = nn.make_causal_mask(jnp.ones((1, self.config.block_size), dtype=\"bool\"), dtype=\"bool\")\n",
    "        c_mask = c_mask[:, :, :query_length, :key_length]\n",
    "        c_mask = jnp.broadcast_to(c_mask, (B,) + c_mask.shape[1:])\n",
    "\n",
    "        attention_bias = jax.lax.select(\n",
    "                c_mask > 0,\n",
    "                jnp.full(c_mask.shape, 0.0).astype(jnp.float32),\n",
    "                jnp.full(c_mask.shape, jnp.finfo(jnp.float32).min).astype(jnp.float32),\n",
    "            )\n",
    "\n",
    "        # use the built in flax libraries to calculate the attention matrix - attention weights are not returned, but could be \n",
    "        # I think bias gives more control compared to mask - i.e. bias can be a float. They might result in the same output with a \n",
    "        # boolean mask, but I will have to test that.\n",
    "        y = nn.dot_product_attention(q, k, v, bias=attention_bias)\n",
    "\n",
    "        # Merge the heads back together\n",
    "        y = y.reshape((B, T, C))\n",
    "\n",
    "        # Project output with a FC layer\n",
    "        y = self.c_proj(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "class GPTBlock(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    def setup(self):\n",
    "        self.ln_1 = nn.LayerNorm(epsilon=1e-05)\n",
    "        # I might have to write this manually to get the proper number of parameters, as the old GPT2 code \n",
    "        # migh have subtle differences from the Flax implementation\n",
    "        self.attn = GPTAttention(self.config)\n",
    "        self.ln_2 = nn.LayerNorm(epsilon=1e-05)\n",
    "        self.mlp = GPTMLP(self.config)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.ln_1(x)\n",
    "        x = inputs + self.attn(x)\n",
    "        inputs2 = x\n",
    "        x = self.ln_2(x)\n",
    "        x = inputs2 + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "class GPTLayers(nn.Module):\n",
    "    config: GPTConfig\n",
    "    \n",
    "    def setup(self):\n",
    "        self.blocks = [ GPTBlock(self.config, name=str(i)) for i in range(self.config.n_layer) ]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    def setup(self):\n",
    "        # This is a little confusing. vocab size is the number of embeddings we need.\n",
    "        # n_embd is the dimension of each embedding (i.e. capacity for learning properties\n",
    "        # about this embedding token)\n",
    "        # input size = (1 x self.block_size) - 1 int for each token\n",
    "        # output size = then (self.block_size x self.n_embd)\n",
    "        self.wte = nn.Embed(self.config.vocab_size, self.config.n_embd)\n",
    "        # embed is just a randomzied parameter matrix, so can be used for positional \n",
    "        # encoding as well. I think block size is the token length.\n",
    "        # This has to match the size of the previous output, as we are just adding.\n",
    "        self.wpe = nn.Embed(self.config.block_size, self.config.n_embd)\n",
    "        # The attention layers\n",
    "        self.h = GPTLayers(self.config)\n",
    "        self.ln_f = nn.LayerNorm(epsilon=1e-05)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        input_shape = jnp.shape(x)       \n",
    "\n",
    "        x = self.wte(x)\n",
    "\n",
    "        # For the positional encodings we need an index that is simple the position\n",
    "        # of each token. This will be the same shape as the input, but will simply\n",
    "        # be repeating and increasing numbers from 1.\n",
    "        # jnp.atleast_2d is needed so we can initialize with a batch size of 1\n",
    "        position_ids = jnp.broadcast_to(jnp.arange(jnp.atleast_2d(inputs).shape[-1]), input_shape)\n",
    "        x_wpe = self.wpe(position_ids)\n",
    "        \n",
    "        x += x_wpe\n",
    "\n",
    "        x = self.h(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    def setup(self):\n",
    "        self.transformer = GPTModel(self.config)\n",
    "        # So the Flax model does not return parameters for lm_head, because lm_head is simply the \n",
    "        # inverse operation of the initial word embedding, so we can just reuse those weights. They\n",
    "        # use the term 'tied' for this. The weights are tied together.\n",
    "        self.lm_head = nn.Dense(self.config.vocab_size, use_bias=False)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # This is from the huggingface code - might as well reuse it here.\n",
    "        shared_kernel = self.transformer.variables['params']['wte']['embedding'].T\n",
    "        lm_logits = self.lm_head.apply({'params': {'kernel': shared_kernel}}, x)\n",
    "        return lm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2 = GPT(GPTConfig)\n",
    "\n",
    "key1, key2 = jax.random.split(jax.random.key(0), 2)\n",
    "\n",
    "# We never want to use int64 as it signficantly slows down training\n",
    "x = np.random.randint(0, 50257, (1,1024), dtype='i4')\n",
    "\n",
    "y = GPT2.init(key2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testConfig:\n",
    "    n_embd = 10\n",
    "    n_head = 2\n",
    "    block_size = 5\n",
    "\n",
    "class testGPTAttention(nn.Module):\n",
    "    config: GPTConfig\n",
    "\n",
    "    # we will need to roll our own attention module because the built in one has a bunch of different\n",
    "    # naming and structure compared to the original GPT, which just references the projection layers\n",
    "    def setup(self):\n",
    "        # The first thing we do is project up to 3x the model size, because we are going to split\n",
    "        # the data into q, v, k\n",
    "        self.c_attn = nn.Einsum((3 * self.config.n_embd, self.config.n_embd), '...ij,...kj->...ik')\n",
    "\n",
    "        # At the end we have to project everything back to the regular model size of n_embd\n",
    "        self.c_proj = nn.Einsum((self.config.n_embd, self.config.n_embd), '...ij,...kj->...ik')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        B, T, C = jnp.shape(x)\n",
    "        \n",
    "        # Project to qkv\n",
    "        qkv = self.c_attn(x)\n",
    "\n",
    "        q, k, v = jnp.split(qkv, 3, axis=2)\n",
    "\n",
    "        query_length, key_length = q.shape[1], k.shape[1]\n",
    "\n",
    "        # Now reshape with a new head \"batch\" dimension\n",
    "        k = jnp.reshape(k, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "        q = jnp.reshape(q, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "        v = jnp.reshape(v, (B, T, self.config.n_head, C // self.config.n_head)) # Shape is (batch, tokens, num_heads, size of head)\n",
    "\n",
    "        # Make the attention mask\n",
    "        # TODO: For round 1 I'm just trusting the linen functions. They seem to be doing the correct thing here, but I may have to \n",
    "        # return to this for a closer look at the math if I'm not getting the GPT2 results\n",
    "        c_mask = nn.make_causal_mask(jnp.ones((1, self.config.block_size), dtype=\"bool\"), dtype=\"bool\")\n",
    "        c_mask = c_mask[:, :, :query_length, :key_length]\n",
    "        c_mask = jnp.broadcast_to(c_mask, (B,) + c_mask.shape[1:])\n",
    "\n",
    "        attention_bias = jax.lax.select(\n",
    "                c_mask > 0,\n",
    "                jnp.full(c_mask.shape, 0.0).astype(jnp.float32),\n",
    "                jnp.full(c_mask.shape, jnp.finfo(jnp.float32).min).astype(jnp.float32),\n",
    "            )\n",
    "\n",
    "        # use the built in flax libraries to calculate the attention matrix - attention weights are not returned, but could be \n",
    "        # I think bias gives more control compared to mask - i.e. bias can be a float. They might result in the same output with a \n",
    "        # boolean mask, but I will have to test that.\n",
    "        y = nn.dot_product_attention(q, k, v, bias=attention_bias)\n",
    "\n",
    "        # Merge the heads back together\n",
    "        y = y.reshape((B, T, C))\n",
    "\n",
    "        # Project output with a FC layer\n",
    "        y = self.c_proj(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class FlaxConv1D(nn.Module):\n",
    "    features: int\n",
    "    use_bias: bool = True\n",
    "    dtype: Any = jnp.float32\n",
    "    precision: Any = None\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        inputs = jnp.asarray(inputs, self.dtype)\n",
    "        kernel = self.param(\"kernel\", jax.nn.initializers.normal(stddev=0.02), (self.features, inputs.shape[-1]))\n",
    "        kernel = jnp.asarray(kernel.transpose(), self.dtype)\n",
    "        y = jax.lax.dot_general(inputs, kernel, (((inputs.ndim - 1,), (0,)), ((), ())), precision=self.precision)\n",
    "        if self.use_bias:\n",
    "            bias = self.param(\"bias\", jax.nn.initializers.zeros, (self.features,))\n",
    "            bias = jnp.asarray(bias, self.dtype)\n",
    "            y = y + bias\n",
    "        return y\n",
    "\n",
    "class FlaxGPT2Attention(nn.Module):\n",
    "    config: testConfig\n",
    "    dtype: jnp.dtype = jnp.float32\n",
    "    causal: bool = True\n",
    "    is_cross_attention: bool = False\n",
    "\n",
    "    def setup(self):\n",
    "        config = self.config\n",
    "        self.embed_dim = config.n_embd\n",
    "        self.num_heads = config.n_head\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        if self.is_cross_attention:\n",
    "            self.c_attn = FlaxConv1D(2 * self.embed_dim, dtype=self.dtype)\n",
    "            self.q_attn = FlaxConv1D(self.embed_dim, dtype=self.dtype)\n",
    "        else:\n",
    "            self.c_attn = FlaxConv1D(3 * self.embed_dim, dtype=self.dtype)\n",
    "        self.c_proj = FlaxConv1D(self.embed_dim, dtype=self.dtype)\n",
    "\n",
    "        if self.causal:\n",
    "            self.causal_mask =nn.make_causal_mask(\n",
    "                jnp.ones((1, config.block_size), dtype=\"bool\"), dtype=\"bool\"\n",
    "            )\n",
    "\n",
    "    def _split_heads(self, hidden_states):\n",
    "        return hidden_states.reshape(hidden_states.shape[:2] + (self.num_heads, self.head_dim))\n",
    "\n",
    "    def _merge_heads(self, hidden_states):\n",
    "        return hidden_states.reshape(hidden_states.shape[:2] + (self.embed_dim,))\n",
    "\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        output_attentions: bool = False,\n",
    "    ):\n",
    "        # if key_value_states are provided this layer is used as a cross-attention layer\n",
    "        # for the decoder\n",
    "        batch_size = hidden_states.shape[0]\n",
    "\n",
    "        qkv_out = self.c_attn(hidden_states)\n",
    "        query, key, value = jnp.split(qkv_out, 3, axis=2)\n",
    "\n",
    "        query = self._split_heads(query)\n",
    "        key = self._split_heads(key)\n",
    "        value = self._split_heads(value)\n",
    "\n",
    "        query_length, key_length = query.shape[1], key.shape[1]\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = self.causal_mask[:, :, :query_length, :key_length]\n",
    "            causal_mask = jnp.broadcast_to(causal_mask, (batch_size,) + causal_mask.shape[1:])\n",
    "\n",
    "        attention_mask = causal_mask\n",
    "\n",
    "        # transform boolean mask into float mask\n",
    "        if attention_mask is not None:\n",
    "            attention_bias = jax.lax.select(\n",
    "                attention_mask > 0,\n",
    "                jnp.full(attention_mask.shape, 0.0).astype(self.dtype),\n",
    "                jnp.full(attention_mask.shape, jnp.finfo(self.dtype).min).astype(self.dtype),\n",
    "            )\n",
    "        else:\n",
    "            attention_bias = None\n",
    "\n",
    "        # usual dot product attention\n",
    "        attn_weights = nn.dot_product_attention_weights(\n",
    "            query,\n",
    "            key,\n",
    "            bias=attention_bias,\n",
    "            dtype=self.dtype,\n",
    "            precision=None,\n",
    "        )\n",
    "\n",
    "        attn_output = jnp.einsum(\"...hqk,...khd->...qhd\", attn_weights, value)\n",
    "        attn_output = self._merge_heads(attn_output)\n",
    "        attn_output = self.c_proj(attn_output)\n",
    "\n",
    "        outputs = (attn_output, attn_weights) if output_attentions else (attn_output,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln1 = testGPTAttention(testConfig)\n",
    "\n",
    "key1, key2 = jax.random.split(jax.random.key(0), 2)\n",
    "\n",
    "# We never want to use int64 as it signficantly slows down training\n",
    "x = np.ones((1, 5, 10))\n",
    "\n",
    "y = ln1.init(key2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln2 = FlaxGPT2Attention(testConfig)\n",
    "\n",
    "key1, key2 = jax.random.split(jax.random.key(0), 2)\n",
    "\n",
    "# We never want to use int64 as it signficantly slows down training\n",
    "x = np.ones((1, 5, 10))\n",
    "\n",
    "y2 = ln2.init(key2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 10)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[[1, 2, 3, 4, 5, 6, 7, 8, 9, 0], [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]])\n",
    "\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.02889265, -0.00587743,  0.013701  , -0.05318468,\n",
       "         -0.01398449,  0.00399514,  0.00705284, -0.01679477,\n",
       "         -0.00136347,  0.00796388],\n",
       "        [-0.04165645, -0.01023988,  0.02881903, -0.07491028,\n",
       "         -0.01374639,  0.00323178,  0.02439473, -0.03530604,\n",
       "         -0.00574531,  0.00888677]]], dtype=float32)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln1.apply({'params': y2['params']}, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[[-0.02889265, -0.00587743,  0.013701  , -0.05318468,\n",
       "          -0.01398449,  0.00399514,  0.00705284, -0.01679477,\n",
       "          -0.00136347,  0.00796388],\n",
       "         [-0.04165644, -0.01023988,  0.02881903, -0.07491027,\n",
       "          -0.01374639,  0.00323177,  0.02439473, -0.03530603,\n",
       "          -0.00574531,  0.00888677]]], dtype=float32),)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln2.apply({'params': y2['params']}, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.38365766e-02, -1.00438399e-02, -2.59855273e-03,\n",
       "        -2.84782257e-02,  2.75602620e-02],\n",
       "       [-5.10251932e-02,  2.19166707e-02, -1.04930252e-02,\n",
       "         7.55112758e-03, -1.42556112e-02],\n",
       "       [ 1.18566537e-02, -1.46680195e-02,  1.62017029e-02,\n",
       "         2.88543049e-02, -1.16017004e-02],\n",
       "       [ 1.61728784e-02, -7.08742533e-03, -1.32274013e-02,\n",
       "        -2.91815065e-02, -5.62517811e-03],\n",
       "       [-3.61472508e-03, -1.01082027e-02,  1.73087647e-05,\n",
       "        -7.02232495e-02,  1.17731094e-02],\n",
       "       [-3.53554785e-02,  1.93876233e-02,  6.20354293e-03,\n",
       "         7.52076088e-03,  6.82975259e-03],\n",
       "       [ 1.06677208e-02,  6.50583627e-03, -9.52924788e-03,\n",
       "         1.89422257e-03, -9.77260433e-03],\n",
       "       [ 2.60021482e-02,  1.21949790e-02,  8.63404572e-03,\n",
       "        -4.96751908e-03, -7.38750445e-03],\n",
       "       [ 1.95287429e-02,  6.33169524e-03, -2.40490027e-02,\n",
       "         9.76687111e-03,  3.65712978e-02],\n",
       "       [-2.29867529e-02, -2.23886129e-02, -3.12390504e-03,\n",
       "        -1.47810709e-02, -2.92127095e-02]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['params']['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = GPT2.apply({'params': model_hf.params}, np.random.randint(0, 50257, (2,1024), dtype='i4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024, 50257)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Neuroscience is \")\n",
    "\n",
    "tokens = jnp.array(tokens, dtype=\"i4\")\n",
    "\n",
    "x = jnp.atleast_2d(tokens).repeat(num_return_sequences, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,\n",
       "          340,   338,   257,  5802,   530,    13,  1892,   691,   326,\n",
       "          475,   340,  1595,   470,   651,  1088,   262,  1109,   326,\n",
       "          661,   508,   389],\n",
       "       [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,\n",
       "         1048,   526, 50256,   464,   649,   512,  1923,   329,   262,\n",
       "         2097,  6796,  5531,  2523,   262,  2097, 10834,  6011,   683,\n",
       "          720,  8054,    11],\n",
       "       [15496,    11,   314,  1101,   257,  3303,  2746,    11,   616,\n",
       "         2460,   290,   314,   389,    13,  3363,    11,  3303, 21128,\n",
       "          318,   257,  5032,    13,   887,  3360,   661,   787, 10135,\n",
       "          351,   340,    13],\n",
       "       [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,\n",
       "          314,  1254,   588,   340,   318,   257,   845,  1593,   636,\n",
       "          286,   616,  1693,   553,   531,  1770,    13,  5741,    13,\n",
       "          366,   464,   517],\n",
       "       [15496,    11,   314,  1101,   257,  3303,  2746,    11,   783,\n",
       "           13,  1320,   338,  1223,   314,   373,  3612,   546,   329,\n",
       "          257,  1790,   981,    13,   314,   588,   340,    11,   290,\n",
       "          314,   765,   284]], dtype=int32)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "key = jax.random.key(57)\n",
    "# This needs to use the jax loop functions to be fast\n",
    "while x.shape[1] < max_length:\n",
    "\n",
    "    logits = GPT2.apply({'params': model_hf.params}, x)\n",
    "\n",
    "    logits = logits[:, -1, :]\n",
    "\n",
    "    #probs = nn.softmax(logits)\n",
    "\n",
    "    topk_probs, topk_indices = jax.lax.top_k(logits, 50)\n",
    "\n",
    "    dist = tfd.Multinomial(1, logits=topk_probs)\n",
    "\n",
    "    key, samp_key = jax.random.split(key)\n",
    "    ix=dist.sample(seed=samp_key)\n",
    "\n",
    "    xcol=jnp.atleast_2d(topk_indices[ix.astype('bool')]).T\n",
    "\n",
    "    x = jnp.append(x, xcol, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = tfd.Multinomial(1, logits=topk_probs)\n",
    "dist.sample(seed=samp_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm a language model, and it's a tough one. Not only that but it doesn't get around the fact that people who are\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode(x[0,:].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = GPT2.apply({'params': model_hf.params}, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 50257)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 50257)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTreeDef({'attn': {'c_attn': {'bias': *, 'kernel': *}, 'c_proj': {'bias': *, 'kernel': *}}, 'ln_1': {'bias': *, 'scale': *}, 'ln_2': {'bias': *, 'scale': *}, 'mlp': {'c_fc': {'bias': *, 'kernel': *}, 'c_proj': {'bias': *, 'kernel': *}}})\n"
     ]
    }
   ],
   "source": [
    "from jax.tree_util import tree_structure\n",
    "print(tree_structure(y['params']['transformer']['h']['0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized parameter shapes:\n",
      " {'h': {'0': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '1': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '2': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '3': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '4': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '5': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}}, 'ln_f': {'bias': (384,), 'scale': (384,)}, 'wpe': {'embedding': (256, 384)}, 'wte': {'embedding': (65, 384)}}\n"
     ]
    }
   ],
   "source": [
    "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(y['params']['transformer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized parameter shapes:\n",
      " {'h': {'0': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '1': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '10': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '11': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '2': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '3': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '4': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '5': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '6': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '7': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '8': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}, '9': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 768)}}, 'ln_1': {'bias': (768,), 'scale': (768,)}, 'ln_2': {'bias': (768,), 'scale': (768,)}, 'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)}, 'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}}, 'ln_f': {'bias': (768,), 'scale': (768,)}, 'wpe': {'embedding': (1024, 768)}, 'wte': {'embedding': (50257, 768)}}\n"
     ]
    }
   ],
   "source": [
    "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(model_hf.params['transformer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like pytorch Linear is not equal to flax Dense. The matrices are defined transpose. So, we can't actually use\n",
    "# Dense with the original GPT2 weights\n",
    "\n",
    "x = jax.random.uniform(jax.random.key(0), (1, 2, 5))\n",
    "\n",
    "# This will transpose the kernel and multiply by the input,\n",
    "# This should be the same as the GPT weights\n",
    "lp = nn.Einsum((3*5, 5), '...ij,...kj->...ik')\n",
    "\n",
    "y = lp.init(jax.random.key(0), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0.40416887, -0.15771458, -0.1418275 ,  0.21624644,\n",
       "          0.01153318,  0.09767484, -0.16552436, -0.06833879,\n",
       "         -0.07042018, -0.13803177, -0.00222424,  0.2503722 ,\n",
       "         -0.3504156 ,  0.18865553, -0.33016038],\n",
       "        [ 0.62610245, -0.35361993, -0.40769407,  0.22174977,\n",
       "          0.1036396 ,  0.2302788 , -0.25040534, -0.5411675 ,\n",
       "         -0.35929912,  0.05858286,  0.03919724,  0.3880062 ,\n",
       "         -0.13242133,  0.4200734 , -0.47516495]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.apply(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp2 = nn.Dense(3*5)\n",
    "\n",
    "y2 = lp2.init(jax.random.key(0), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized parameter shapes:\n",
      " {'transformer': {'h': {'0': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '1': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '2': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '3': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '4': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}, '5': {'attn': {'c_attn': {'bias': (1152,), 'kernel': (1152, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 384)}}, 'ln_1': {'bias': (384,), 'scale': (384,)}, 'ln_2': {'bias': (384,), 'scale': (384,)}, 'mlp': {'c_fc': {'bias': (1536,), 'kernel': (1536, 384)}, 'c_proj': {'bias': (384,), 'kernel': (384, 1536)}}}}, 'ln_f': {'bias': (384,), 'scale': (384,)}, 'wpe': {'embedding': (256, 384)}, 'wte': {'embedding': (65, 384)}}}\n"
     ]
    }
   ],
   "source": [
    "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(y['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': {'h': {'0': {'attn': {'c_attn': {'bias': (2304,),\n",
       "      'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '1': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '10': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '11': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '2': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '3': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '4': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '5': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '6': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '7': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '8': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '9': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}},\n",
       "  'ln_f': {'bias': (768,), 'scale': (768,)},\n",
       "  'wpe': {'embedding': (1024, 768)},\n",
       "  'wte': {'embedding': (50257, 768)}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree.map(lambda x: x.shape, y['params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': {'h': {'0': {'attn': {'c_attn': {'bias': (2304,),\n",
       "      'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '1': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '10': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '11': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '2': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '3': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '4': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '5': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '6': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '7': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '8': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}},\n",
       "   '9': {'attn': {'c_attn': {'bias': (2304,), 'kernel': (2304, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 768)}},\n",
       "    'ln_1': {'bias': (768,), 'scale': (768,)},\n",
       "    'ln_2': {'bias': (768,), 'scale': (768,)},\n",
       "    'mlp': {'c_fc': {'bias': (3072,), 'kernel': (3072, 768)},\n",
       "     'c_proj': {'bias': (768,), 'kernel': (768, 3072)}}}},\n",
       "  'ln_f': {'bias': (768,), 'scale': (768,)},\n",
       "  'wpe': {'embedding': (1024, 768)},\n",
       "  'wte': {'embedding': (50257, 768)}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree.map(lambda x: x.shape, model_hf.params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
