{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from collections.abc import Iterator\n",
    "from typing import Mapping, NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "def net_fn(images: jax.Array, is_training: bool) -> jax.Array:\n",
    "  # normalize the images\n",
    "  x = images.astype(jnp.float32) / 255.0 \n",
    "\n",
    "  # The most simple network - Flatten the image and pass through some\n",
    "  # convolutions, a mlp, and output the 10 categories as logits\n",
    "  cnet1 = hk.Sequential([\n",
    "    hk.Conv2D(32, (3, 3)), jax.nn.relu,\n",
    "    hk.MaxPool((2,2), 2, \"SAME\"),\n",
    "  ])\n",
    "\n",
    "  cnet2 = hk.Sequential([\n",
    "    hk.Conv2D(32, (3, 3)), jax.nn.relu,\n",
    "    hk.MaxPool((2,2), 2, \"SAME\"),\n",
    "    hk.Conv2D(32, (3, 3)), jax.nn.relu,\n",
    "  ])\n",
    "\n",
    "  dnet = hk.Sequential([\n",
    "    hk.Flatten(),\n",
    "    hk.Linear(64), jax.nn.relu,\n",
    "    hk.Linear(32), jax.nn.relu,\n",
    "    hk.Linear(NUM_CLASSES),\n",
    "  ])\n",
    "\n",
    "  x = cnet1(x)\n",
    "\n",
    "  if is_training:\n",
    "    x = hk.dropout(hk.next_rng_key(), 0.5, x)\n",
    "\n",
    "  x = cnet2(x)\n",
    "\n",
    "  if is_training:\n",
    "    x = hk.dropout(hk.next_rng_key(), 0.5, x)\n",
    "\n",
    "  return dnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following the haiku examples, we define a class that inherets NamedTuple and this will hold\n",
    "# our data. It basically redefines a dictionary to a class for typing purposes I presume. Type\n",
    "# checking improves readablity and maintenance / bug-fixing\n",
    "class Batch(NamedTuple):\n",
    "  image: np.ndarray  # [B, H, W, 1]\n",
    "  label: np.ndarray  # [B]\n",
    "\n",
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    is_training: bool,\n",
    "    batch_size: int,) -> (Iterator[Batch], Mapping):\n",
    "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
    "  ds, ds_info = tfds.load(\"cifar10:3.*.*\", split=split, with_info=True)\n",
    "  ds = ds.cache()\n",
    "  if is_training:\n",
    "    ds = ds.shuffle(ds_info.splits[split].num_examples, seed=0)\n",
    "    ds = ds.repeat() # We want an infinite iterator of the data\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.map(lambda x: Batch(x['image'], x['label'])) # ** operator unpacks a dictionary\n",
    "  return iter(tfds.as_numpy(ds)), ds_info\n",
    "\n",
    "train, ds_info = load_dataset(\"train\", is_training=True, batch_size=256)\n",
    "\n",
    "test, ds_info = load_dataset(\"test\", is_training=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    full_name='cifar10/3.0.2',\n",
      "    description=\"\"\"\n",
      "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
      "    \"\"\",\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    data_dir='/home/don/tensorflow_datasets/cifar10/3.0.2',\n",
      "    file_format=tfrecord,\n",
      "    download_size=162.17 MiB,\n",
      "    dataset_size=132.40 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'id': Text(shape=(), dtype=string),\n",
      "        'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss 2.3306 Test acc 0.0000\n",
      "Epoch 501 Train Loss 1.8394 Test acc 0.0000\n",
      "Epoch 1001 Train Loss 1.6910 Test acc 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/don/ML_Tests/cifar_convnet.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m     state, loss \u001b[39m=\u001b[39m update(state, \u001b[39mnext\u001b[39m(train))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     train_loss(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m       \u001b[39m#test, ds_info = load_dataset(\"test\", is_training=False, batch_size=64)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m       \u001b[39m#for b in test:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m       \u001b[39m#  acc = evaluate(state.params, b)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m       \u001b[39m#  test_acc(acc)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/don/ML_Tests/cifar_convnet.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Train Loss \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m.\u001b[39mresult()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Test acc \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m.\u001b[39mresult()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/metrics/base_metric.py:216\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[39mreturn\u001b[39;00m result_t\n\u001b[1;32m    212\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    213\u001b[0m     distributed_training_utils,\n\u001b[1;32m    214\u001b[0m )\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m distributed_training_utils\u001b[39m.\u001b[39;49mcall_replica_local_fn(\n\u001b[1;32m    217\u001b[0m     replica_local_fn, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    218\u001b[0m )\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/distribute/distributed_training_utils.py:62\u001b[0m, in \u001b[0;36mcall_replica_local_fn\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mwith\u001b[39;00m strategy\u001b[39m.\u001b[39mscope():\n\u001b[1;32m     61\u001b[0m         \u001b[39mreturn\u001b[39;00m strategy\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcall_for_each_replica(fn, args, kwargs)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/metrics/base_metric.py:187\u001b[0m, in \u001b[0;36mMetric.__call__.<locals>.replica_local_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     update_op \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     update_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_state(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    188\u001b[0m update_ops \u001b[39m=\u001b[39m []\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py:77\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mscope. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 77\u001b[0m     update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/metrics/base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    137\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m    138\u001b[0m     obj_update_state, control_status\n\u001b[1;32m    139\u001b[0m )\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/keras/src/metrics/base_metric.py:485\u001b[0m, in \u001b[0;36mReduce.update_state\u001b[0;34m(self, values, sample_weight)\u001b[0m\n\u001b[1;32m    479\u001b[0m [\n\u001b[1;32m    480\u001b[0m     values\n\u001b[1;32m    481\u001b[0m ], sample_weight \u001b[39m=\u001b[39m metrics_utils\u001b[39m.\u001b[39mragged_assert_compatible_and_get_flat_values(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     [values], sample_weight\n\u001b[1;32m    483\u001b[0m )\n\u001b[1;32m    484\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m     values \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcast(values, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[1;32m    486\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    487\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    488\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe output of a metric function can only be a single Tensor. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1009\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1003\u001b[0m   x \u001b[39m=\u001b[39m indexed_slices\u001b[39m.\u001b[39mIndexedSlices(values_cast, x\u001b[39m.\u001b[39mindices, x\u001b[39m.\u001b[39mdense_shape)\n\u001b[1;32m   1004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m   \u001b[39m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m   \u001b[39m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m   \u001b[39m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m   \u001b[39m# strings.\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(x, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1010\u001b[0m   \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39mand\u001b[39;00m base_type\u001b[39m.\u001b[39mis_floating:\n\u001b[1;32m   1011\u001b[0m     logging\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1012\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are casting an input of type \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m to an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible dtype \u001b[39m\u001b[39m{\u001b[39;00mbase_type\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.  This will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1014\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdiscard the imaginary part and may not be what you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1015\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mintended.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m     )\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[0;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[1;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m   1445\u001b[0m )\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    284\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    286\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/jax/_src/array.py:373\u001b[0m, in \u001b[0;36mArrayImpl.__array__\u001b[0;34m(self, dtype, context)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 373\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_value, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/jax/lib/python3.9/site-packages/jax/_src/array.py:562\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 562\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_device_array_to_np_array()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(np\u001b[39m.\u001b[39mndarray, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We should now turn this into a proper training loop.\n",
    "import tensorflow as tf\n",
    "#tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "  params: hk.Params\n",
    "  rng_key: jax.Array\n",
    "  opt_state: optax.OptState\n",
    "\n",
    "SEED = 5\n",
    "\n",
    "EPOCHS = 4000\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimiser = optax.adam(LEARNING_RATE)\n",
    "\n",
    "# When there is no rng you can have hk handle this for you with without_apply_rng\n",
    "net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "#net = hk.transform(net_fn)\n",
    "\n",
    "# Training loss (cross-entropy). - right from the examples. pretty simple function\n",
    "@hk.transform\n",
    "def my_loss(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "  logits = net_fn(batch.image, True)\n",
    "  labels = jax.nn.one_hot(batch.label, NUM_CLASSES)\n",
    "\n",
    "  #l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(state.params))\n",
    "  softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "  softmax_xent /= labels.shape[0] # Using the average of the batch. This is why increased batch size tends to regularize your networks as well.\n",
    "                                  # More data makes the loss function \"smoother\". It is less likely to overfit to small numbers of cases and \n",
    "                                  # get stuck in local minimums.\n",
    "\n",
    "  return softmax_xent #+ 1e-3 * l2_loss\n",
    "  #return softmax_xent\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params: hk.Params, batch: Batch) -> jax.Array:\n",
    "  \"\"\"Evaluation metric (classification accuracy).\"\"\"\n",
    "  logits = net.apply(params, batch.image, False)\n",
    "  predictions = jnp.argmax(logits, axis=-1)\n",
    "  return jnp.mean(predictions == batch.label)\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    state: TrainingState,\n",
    "    batch: Batch,\n",
    ") -> (TrainingState, float):\n",
    "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "  rng, net_rng = jax.random.split(state.rng_key)\n",
    "  loss_and_grad_fn = jax.value_and_grad(my_loss.apply)\n",
    "  loss, grads = loss_and_grad_fn(state.params, net_rng, batch)\n",
    "  updates, opt_state = optimiser.update(grads, state.opt_state)\n",
    "  new_params = optax.apply_updates(state.params, updates)\n",
    "  return TrainingState(new_params, rng, opt_state), loss\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_loss.reset_states()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_loss.reset_states()\n",
    "\n",
    "test_acc = tf.keras.metrics.Mean(name='test_acc')\n",
    "test_acc.reset_states()\n",
    "\n",
    "example = next(train)\n",
    "\n",
    "rng = jax.random.PRNGKey(SEED)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Get the initial parameters\n",
    "params = my_loss.init(init_rng, example)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "state = TrainingState(params, rng, opt_state)\n",
    "\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    state, loss = update(state, next(train))\n",
    "    train_loss(loss)\n",
    "\n",
    "    if step % 500 == 0:\n",
    "      #test, ds_info = load_dataset(\"test\", is_training=False, batch_size=64)\n",
    "      #for b in test:\n",
    "      #  acc = evaluate(state.params, b)\n",
    "      #  test_acc(acc)\n",
    "      print(f'Epoch {step + 1} Train Loss {train_loss.result():.4f} Test acc {test_acc.result():.4f}')\n",
    "      #logging.info({train_loss: train_loss})\n",
    "      #test_acc.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ML-tests': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b163f0480e5ecb2ed0d5f04556597a429b2f653f97b785151c27d861fe015d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
